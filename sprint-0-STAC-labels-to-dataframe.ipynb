{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial Data Processing and Vegetation Index Calculation\n",
    "\n",
    "### Description\n",
    "\n",
    "This Jupyter Notebook aims to construct a pandas DataFrame containing labeled geospatial data enriched with reflectance values and vegetation indices derived from the label source data. The notebook leverages the SpatioTemporal Asset Catalog (STAC) API to access geospatial datasets, and various Python libraries like pystac_client, geopandas, and rasterio to manipulate the data.\n",
    "\n",
    "### Sections\n",
    "\n",
    "* **Setting up the Environment**: The notebook starts by importing the required Python libraries and specifying the STAC API endpoint.\n",
    "\n",
    "* **Data Retrieval from STAC API**: The notebook connects to the STAC API and retrieves labeled geospatial datasets related to the \"ai-extensions-svv-dataset-labels\" collection.\n",
    "\n",
    "* **Utility Functions**: This section defines utility functions for calculating normalized differences (NDVI, NDWI1, NDWI2) and reading geojson data from an AWS S3 bucket.\n",
    "\n",
    "* **Data Sampling and Processing**: Each labeled geospatial item is processed to sample reflectance values from different spectral bands, such as \"coastal\", \"red\", \"green\", \"blue\", \"nir\", \"nir08\", \"nir09\", \"swir16\", and \"swir22\". The notebook then calculates vegetation indices like NDVI, NDWI1, and NDWI2 based on the sampled data.\n",
    "\n",
    "* **Creating Enriched DataFrame**: The processed data is organized into a pandas DataFrame, which combines the labeled geospatial data with reflectance values and vegetation indices.\n",
    "\n",
    "* **Data Description and Saving**: The notebook provides a descriptive summary of the enriched DataFrame, including statistics and characteristics of the data. The DataFrame is then saved as a pickle file for further analysis and visualization.\n",
    "\n",
    "By following the steps in this notebook, users can obtain a comprehensive DataFrame that contains labeled geospatial data with additional valuable information, such as reflectance values and vegetation indices. This DataFrame can serve as a foundation for various geospatial analysis tasks, including land cover classification, vegetation health monitoring, and environmental assessment. Users can adapt the notebook to work with different datasets and explore other geospatial analytics techniques based on their specific requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from utils import (\n",
    "    UserSettings,\n",
    "    get_asset_by_common_name,\n",
    "    convert_coordinates,\n",
    ")\n",
    "from pystac import read_file\n",
    "from urllib.parse import urlparse\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import boto3, botocore\n",
    "import io\n",
    "import os\n",
    "from pystac.stac_io import DefaultStacIO, StacIO\n",
    "import rasterio\n",
    "from pystac import Item\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establishes a client for the STAC API endpoint using the pystac library. The cat object is created as a client representation of the STAC catalog at the specified stac_endpoint. This enables interaction with the API and exploration of available items and collections within the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_endpoint = \"https://stac-api-dev.terradue.com/\"\n",
    "\n",
    "headers = []\n",
    "\n",
    "cat = Client.open(stac_endpoint, headers=headers, ignore_conformance=True)\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A search query is performed on the STAC API using the pystac library. The collections variable is set to [\"ai-extensions-svv-dataset-labels\"], indicating that we are interested in searching for items within the \"ai-extensions-svv-dataset-labels\" collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = [\"ai-extensions-svv-dataset-labels\"]\n",
    "\n",
    "query = cat.search(collections=collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list comprehension iterates over each item in the query.item_collection() and retrieves the \"labels\" asset for each item using the get_assets() method. The result is a list of \"labels\" assets for all items in the collection that matched the search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item.get_assets()[\"labels\"] for item in query.item_collection()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code sets up user settings using a JSON file named \"usersettings.json\" and sets the AWS S3 environment using an asset URL obtained from the first item in the search query result.\n",
    "\n",
    "`UserSettings(\"usersettings.json\")`: A UserSettings object is created, which reads the user settings from the \"usersettings.json\" file. This file presumably contains various configurations needed for the script.\n",
    "\n",
    "`settings.set_s3_environment(...)`: The set_s3_environment() method is called on the settings object, passing the absolute URL of the \"labels\" asset of the first item in the search query result (`query.item_collection()[0].get_assets()[\"labels\"].get_absolute_href()`). This method presumably sets up the AWS S3 environment using the provided asset URL, which might include authentication credentials and other necessary parameters.\n",
    "\n",
    "`print(os.environ[\"AWS_ACCESS_KEY_ID\"])`: This line prints the value of the \"AWS_ACCESS_KEY_ID\" environment variable. Since this variable was likely set during the `set_s3_environment()` call in the UserSettings object, it will display the corresponding AWS Access Key ID value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = UserSettings(\"usersettings.json\")\n",
    "\n",
    "settings.set_s3_environment(\n",
    "    query.item_collection()[0].get_assets()[\"labels\"].get_absolute_href()\n",
    ")\n",
    "\n",
    "print(os.environ[\"AWS_ACCESS_KEY_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StacIO.set_default(DefaultStacIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create normalized difference function\n",
    "def nd(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the normalized difference between two values a and b.\n",
    "\n",
    "    Parameters:\n",
    "        a (numeric): The first value.\n",
    "        b (numeric): The second value.\n",
    "\n",
    "    Returns:\n",
    "        float: The normalized difference between a and b.\n",
    "\n",
    "    Example:\n",
    "        ndvi_value = nd(nir_value, red_value)\n",
    "    \"\"\"\n",
    "    return (a - b) / (a + b)\n",
    "\n",
    "\n",
    "def read_geojson(\n",
    "    label_item: Item, user_settings=\"usersettings.json\", asset_key=\"labels\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads GeoJSON data from an S3 bucket.\n",
    "\n",
    "    Parameters:\n",
    "        label_item (object): Item representing the GeoJSON data with S3 asset link.\n",
    "        user_settings (str, optional): Path to the user settings file. Default is \"usersettings.json\".\n",
    "        asset_key (str, optional): Key to access the GeoJSON asset within the label_item. Default is \"labels\".\n",
    "\n",
    "    Returns:\n",
    "        geopandas.GeoDataFrame: A GeoDataFrame containing the geometries and attributes from the GeoJSON data.\n",
    "\n",
    "    Raises:\n",
    "        botocore.exceptions.NoCredentialsError: If AWS credentials are missing or invalid.\n",
    "        botocore.exceptions.EndpointConnectionError: If there is an issue connecting to the AWS S3 endpoint.\n",
    "        botocore.exceptions.BotoCoreError: For general BotoCore errors related to AWS S3 interactions.\n",
    "        geopandas.errors.GeoPandasError: If there is an error reading the GeoJSON data into a GeoDataFrame.\n",
    "\n",
    "    Example:\n",
    "        label_data = read_geojson(label_item, user_settings=\"path/to/usersettings.json\", asset_key=\"geojson_data\")\n",
    "    \"\"\"\n",
    "    settings = UserSettings(user_settings)\n",
    "\n",
    "    settings.set_s3_environment(label_item.get_assets()[asset_key].get_absolute_href())\n",
    "    session = botocore.session.Session()\n",
    "\n",
    "    s3_client = session.create_client(\n",
    "        service_name=\"s3\",\n",
    "        region_name=os.environ.get(\"AWS_REGION\"),\n",
    "        use_ssl=True,\n",
    "        endpoint_url=os.environ.get(\"AWS_S3_ENDPOINT\"),\n",
    "        aws_access_key_id=os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "        aws_secret_access_key=os.environ.get(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    )\n",
    "\n",
    "    parsed = urlparse(label_item.get_assets()[asset_key].get_absolute_href())\n",
    "\n",
    "    bucket = parsed.netloc\n",
    "    key = parsed.path[1:]\n",
    "\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "    return gpd.read_file(io.BytesIO(obj[\"Body\"].read()))\n",
    "\n",
    "\n",
    "def sample_data(label_item, source_item=None, common_bands=[\"red\", \"nir\"]):\n",
    "    \"\"\"\n",
    "    Samples raster data at specified geometries and calculates spectral indices for each point.\n",
    "\n",
    "    Parameters:\n",
    "        label_item (object): GeoJSON data containing geometries to be sampled.\n",
    "        source_item (object, optional): Raster data file to be sampled. If not provided, it will be inferred from links in label_item. Default is None.\n",
    "        common_bands (list, optional): List of band names to be read from the raster file. Default is [\"red\", \"nir\"].\n",
    "\n",
    "    Returns:\n",
    "        geopandas.GeoDataFrame: A GeoDataFrame containing the sampled raster values and calculated spectral indices.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the source_item is not provided and cannot be inferred from links in label_item.\n",
    "        ValueError: If any of the common_bands are not available in the raster data file.\n",
    "\n",
    "    Example:\n",
    "        label_data = read_geojson(\"path/to/label.geojson\")\n",
    "        raster_data = read_file(\"path/to/raster.tif\")\n",
    "        sampled_data = sample_data(label_data, source_item=raster_data, common_bands=[\"red\", \"nir\", \"swir16\"])\n",
    "    \"\"\"\n",
    "    gdf = read_geojson(label_item)\n",
    "\n",
    "    if source_item is None:\n",
    "        source_item = read_file(\n",
    "            [link.target for link in label_item.get_links() if link.rel in [\"source\"]][\n",
    "                0\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    dataset = {}\n",
    "    for common_band in common_bands:\n",
    "        logger.info(f\"Reading {common_band} band\")\n",
    "        dataset[common_band] = rasterio.open(\n",
    "            get_asset_by_common_name(source_item, common_band).get_absolute_href()\n",
    "        )\n",
    "\n",
    "    def convert_row(row, target_crs):\n",
    "        \"EPSG:4326\"\n",
    "        longitude = row.geometry.x\n",
    "        latitude = row.geometry.y\n",
    "\n",
    "        src_crs = \"EPSG:4326\"\n",
    "\n",
    "        row[\"utm_x\"], row[\"utm_y\"] = convert_coordinates(\n",
    "            src_crs, target_crs, longitude, latitude\n",
    "        )\n",
    "\n",
    "        return pd.Series(row)\n",
    "\n",
    "    crs_info = dataset[common_bands[0]].crs\n",
    "    target_crs = f\"EPSG:{crs_info.to_epsg()}\"\n",
    "    gdf = gdf.apply(convert_row, target_crs=target_crs, axis=1)\n",
    "\n",
    "    points_utm = [(x, y) for x, y in zip(gdf[\"utm_x\"], gdf[\"utm_y\"])]\n",
    "\n",
    "    for common_band in common_bands:\n",
    "        logger.info(f\"Sampling {common_band} band\")\n",
    "        gdf[common_band] = [\n",
    "            val[0] / 10000 for val in dataset[common_band].sample(points_utm, 1)\n",
    "        ]\n",
    "\n",
    "    if \"red\" in common_bands and \"nir\" in common_bands:\n",
    "        gdf[\"ndvi\"] = nd(gdf[\"nir\"], gdf[\"red\"])\n",
    "    if \"green\" in common_bands and \"nir\" in common_bands:\n",
    "        gdf[\"ndwi1\"] = nd(gdf[\"green\"], gdf[\"nir\"])\n",
    "    if \"nir\" in common_bands and \"swir16\" in common_bands:\n",
    "        gdf[\"ndwi2\"] = nd(gdf[\"nir\"], gdf[\"swir16\"])\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs data sampling from the items retrieved in the search query result (query.item_collection()). The sampled data for each item is appended to a list named `tmp_gdfs``, and finally, all the data is concatenated into a pandas DataFrame named `gdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_gdfs = []\n",
    "\n",
    "for label_item in query.item_collection():\n",
    "\n",
    "    sampled_data = sample_data(label_item=label_item, common_bands=[\"coastal\", \"red\", \"green\", \"blue\", \"nir\", \"nir08\", \"nir09\", \"swir16\", \"swir22\"])\n",
    "    \n",
    "    tmp_gdfs.append(sampled_data)\n",
    "\n",
    "gdf = pd.concat(tmp_gdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_pickle('sprint-0-STAC-labels-to-dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
