{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial Data Processing and Vegetation Index Calculation\n",
    "\n",
    "### Description\n",
    "\n",
    "This Jupyter Notebook aims to construct a pandas DataFrame containing labeled geospatial data enriched with reflectance values and vegetation indices derived from the label source data. The notebook leverages the SpatioTemporal Asset Catalog (STAC) API to access geospatial datasets, and various Python libraries like pystac_client, geopandas, and rasterio to manipulate the data.\n",
    "\n",
    "### Sections\n",
    "\n",
    "* **Setting up the Environment**: The notebook starts by importing the required Python libraries and specifying the STAC API endpoint.\n",
    "\n",
    "* **Data Retrieval from STAC API**: The notebook connects to the STAC API and retrieves labeled geospatial datasets related to the \"ai-extensions-svv-dataset-labels\" collection.\n",
    "\n",
    "* **Utility Functions**: This section defines utility functions for calculating normalized differences (NDVI, NDWI1, NDWI2) and reading geojson data from an AWS S3 bucket.\n",
    "\n",
    "* **Data Sampling and Processing**: Each labeled geospatial item is processed to sample reflectance values from different spectral bands, such as \"coastal\", \"red\", \"green\", \"blue\", \"nir\", \"nir08\", \"nir09\", \"swir16\", and \"swir22\". The notebook then calculates vegetation indices like NDVI, NDWI1, and NDWI2 based on the sampled data.\n",
    "\n",
    "* **Creating Enriched DataFrame**: The processed data is organized into a pandas DataFrame, which combines the labeled geospatial data with reflectance values and vegetation indices.\n",
    "\n",
    "* **Data Description and Saving**: The notebook provides a descriptive summary of the enriched DataFrame, including statistics and characteristics of the data. The DataFrame is then saved as a pickle file for further analysis and visualization.\n",
    "\n",
    "By following the steps in this notebook, users can obtain a comprehensive DataFrame that contains labeled geospatial data with additional valuable information, such as reflectance values and vegetation indices. This DataFrame can serve as a foundation for various geospatial analysis tasks, including land cover classification, vegetation health monitoring, and environmental assessment. Users can adapt the notebook to work with different datasets and explore other geospatial analytics techniques based on their specific requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from utils import (\n",
    "    UserSettings,\n",
    "    get_asset_by_common_name,\n",
    "    convert_coordinates,\n",
    ")\n",
    "from pystac import read_file\n",
    "from urllib.parse import urlparse\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import boto3, botocore\n",
    "import io\n",
    "import os\n",
    "from pystac.stac_io import DefaultStacIO, StacIO\n",
    "import rasterio\n",
    "from pystac import Item\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_endpoint = \"https://stac-api-dev.terradue.com/\"\n",
    "\n",
    "headers = []\n",
    "\n",
    "cat = Client.open(stac_endpoint, headers=headers, ignore_conformance=True)\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = [\"ai-extensions-svv-dataset-labels\"]\n",
    "\n",
    "query = cat.search(collections=collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item.get_assets()[\"labels\"] for item in query.item_collection()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = UserSettings(\"usersettings.json\")\n",
    "\n",
    "settings.set_s3_environment(\n",
    "    query.item_collection()[0].get_assets()[\"labels\"].get_absolute_href()\n",
    ")\n",
    "\n",
    "print(os.environ[\"AWS_ACCESS_KEY_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StacIO.set_default(DefaultStacIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_item = query.item_collection()[0]\n",
    "label_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_item.get_assets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create normalized difference function\n",
    "def nd(a, b):\n",
    "    return (a - b) / (a + b)\n",
    "\n",
    "\n",
    "def read_geojson(\n",
    "    label_item: Item, user_settings=\"usersettings.json\", asset_key=\"labels\"\n",
    "):\n",
    "    settings = UserSettings(user_settings)\n",
    "\n",
    "    settings.set_s3_environment(label_item.get_assets()[asset_key].get_absolute_href())\n",
    "    session = botocore.session.Session()\n",
    "\n",
    "    s3_client = session.create_client(\n",
    "        service_name=\"s3\",\n",
    "        region_name=os.environ.get(\"AWS_REGION\"),\n",
    "        use_ssl=True,\n",
    "        endpoint_url=os.environ.get(\"AWS_S3_ENDPOINT\"),\n",
    "        aws_access_key_id=os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "        aws_secret_access_key=os.environ.get(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    )\n",
    "\n",
    "    parsed = urlparse(label_item.get_assets()[asset_key].get_absolute_href())\n",
    "\n",
    "    bucket = parsed.netloc\n",
    "    key = parsed.path[1:]\n",
    "\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "    return gpd.read_file(io.BytesIO(obj[\"Body\"].read()))\n",
    "\n",
    "\n",
    "def sample_data(label_item, source_item=None, common_bands=[\"red\", \"nir\"]):\n",
    "    gdf = read_geojson(label_item)\n",
    "\n",
    "    if source_item is None:\n",
    "        source_item = read_file(\n",
    "            [link.target for link in label_item.get_links() if link.rel in [\"source\"]][\n",
    "                0\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    dataset = {}\n",
    "    for common_band in common_bands:\n",
    "        logger.info(f\"Reading {common_band} band\")\n",
    "        dataset[common_band] = rasterio.open(\n",
    "            get_asset_by_common_name(source_item, common_band).get_absolute_href()\n",
    "        )\n",
    "\n",
    "    def convert_row(row, target_crs):\n",
    "        \"EPSG:4326\"\n",
    "        longitude = row.geometry.x\n",
    "        latitude = row.geometry.y\n",
    "\n",
    "        src_crs = \"EPSG:4326\"\n",
    "\n",
    "        row[\"utm_x\"], row[\"utm_y\"] = convert_coordinates(\n",
    "            src_crs, target_crs, longitude, latitude\n",
    "        )\n",
    "\n",
    "        return pd.Series(row)\n",
    "\n",
    "    crs_info = dataset[common_bands[0]].crs\n",
    "    target_crs = f\"EPSG:{crs_info.to_epsg()}\"\n",
    "    gdf = gdf.apply(convert_row, target_crs=target_crs, axis=1)\n",
    "\n",
    "    points_utm = [(x, y) for x, y in zip(gdf[\"utm_x\"], gdf[\"utm_y\"])]\n",
    "\n",
    "    for common_band in common_bands:\n",
    "        logger.info(f\"Sampling {common_band} band\")\n",
    "        gdf[common_band] = [\n",
    "            val[0] / 10000 for val in dataset[common_band].sample(points_utm, 1)\n",
    "        ]\n",
    "\n",
    "    if \"red\" in common_bands and \"nir\" in common_bands:\n",
    "        gdf[\"ndvi\"] = nd(gdf[\"nir\"], gdf[\"red\"])\n",
    "    if \"green\" in common_bands and \"nir\" in common_bands:\n",
    "        gdf[\"ndwi1\"] = nd(gdf[\"green\"], gdf[\"nir\"])\n",
    "    if \"nir\" in common_bands and \"swir16\" in common_bands:\n",
    "        gdf[\"ndwi2\"] = nd(gdf[\"nir\"], gdf[\"swir16\"])\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_gdfs = []\n",
    "\n",
    "for label_item in query.item_collection():\n",
    "\n",
    "    sampled_data = sample_data(label_item=label_item, common_bands=[\"coastal\", \"red\", \"green\", \"blue\", \"nir\", \"nir08\", \"nir09\", \"swir16\", \"swir22\"])\n",
    "    \n",
    "    tmp_gdfs.append(sampled_data)\n",
    "\n",
    "gdf = pd.concat(tmp_gdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_pickle('sprint-0-STAC-labels-to-dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
